{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first line:  ﻿The Project Gutenberg eBook of A Room With A View, by E. M. Forster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"datasets/a_room_with_a_view.txt\", \"r\", encoding = \"utf8\")\n",
    "lines = []\n",
    "\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "    \n",
    "print(\"The first line: \", lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Romove escape characters and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of A Room With A View  by E  M  Forster  This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever  You may copy it  give it away or re use it under the terms of the Project Gutenberg License included with this eBook or online at www gutenberg org  If you are not located in the United States  you will have to check the laws of the country where you are located before using '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"\"\n",
    "\n",
    "for i in lines:\n",
    "    data = ' '. join(lines)\n",
    "    \n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "data[:360]\n",
    "\n",
    "import string\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "data = data.translate(translator)\n",
    "\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"I am a good boy with handrads of friends\"\n",
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "tokenized = tokenizer.tokenize(data)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁and', '▁red', '▁bottles', '▁of', '▁wine', '▁that', '▁ran', '▁between', '▁the', '▁English', '▁people', '▁at', '▁the', '▁portraits', '▁of', '▁the', '▁late', '▁Queen', '▁and', '▁the']\n",
      "[21, 1170, 10596, 20, 2680, 29, 1662, 161, 18, 897, 104, 38, 18, 16738, 20, 18, 471, 3631, 21, 18]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized[512:532])\n",
    "print(tokenizer.convert_tokens_to_ids(tokenized[512:532]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_arr = np.array(ids)\n",
    "\n",
    "sequences = np.empty((0,4))\n",
    "for i in range(3, len(ids)):\n",
    "    words = np.expand_dims(ids_arr[i-3:i+1], axis=0)\n",
    "    sequences = np.append(sequences, words,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    Y.append(i[3])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = np.eye(vocab_size)[Y.astype(int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = vocab_size\n",
    "sequence_length = 3\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "embedding_dim = 10\n",
    "load_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embed = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        rnn_in = self.embed(x)\n",
    "#         rnn_in = rnn_in.unsqueeze(1)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.rnn(rnn_in, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17483\n",
      "[[3.2000e+01 3.4830e+03 2.1054e+04]\n",
      " [3.4830e+03 2.1054e+04 6.7510e+03]\n",
      " [2.1054e+04 6.7510e+03 2.8983e+04]\n",
      " [6.7510e+03 2.8983e+04 2.0000e+01]\n",
      " [2.8983e+04 2.0000e+01 7.9000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "num_train = len(X)*2//10\n",
    "print(num_train)\n",
    "# train_x = np.expand_dims(X[:num_train], axis=2)\n",
    "# test_x = np.expand_dims(X[num_train:], axis=2)\n",
    "train_x = X[:num_train]\n",
    "test_x = X[num_train:]\n",
    "print(train_x[:5])\n",
    "\n",
    "train_y = Y[:num_train]\n",
    "test_y = Y[num_train:]\n",
    "\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network (try out just using simple RNN, or GRU, and then compare with LSTM)\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "=> Saving checkpoint\n",
      "Epoch: 1, Loss: 1.687454989005136\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    if epoch % 3 == 0:\n",
    "        checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "        # Try save checkpoint\n",
    "        save_checkpoint(checkpoint)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "#         data = data.to(device=device).squeeze(1)\n",
    "#         print(data.shape)\n",
    "        \n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data.long())\n",
    "        loss = criterion(scores, targets.long())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent update step/adam step\n",
    "        optimizer.step()\n",
    "        epoch_loss += data.shape[0] * loss.item()\n",
    "#         print(f\"Batch: {epoch+1}, Loss: {loss.item()}\")\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {float(epoch_loss) / float(len(train))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.000000\n",
      "Accuracy on test set: 0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    # Set model to eval\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x.long())\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y.long()).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    # Toggle model back to train\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n",
    "\n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10369.   868.   107.]\n",
      "[10369, 868, 107]\n",
      "615\n",
      "['▁rushing', '▁below', '▁them']\n",
      "['▁almost']\n"
     ]
    }
   ],
   "source": [
    "idx = num_train-20\n",
    "ids_x = X[idx]\n",
    "ids_y = Y[idx]\n",
    "input_x = ids_x.astype(int).tolist()\n",
    "output_y = ids_y.astype(int).tolist()\n",
    "print(tokenizer.convert_ids_to_tokens(input_x))\n",
    "print(tokenizer.convert_ids_to_tokens([output_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[615,  31,  17,  20,  21,  18, 280, 200, 175,  35,  34, 102]])\n",
      "tensor([[0.8662, 0.0245, 0.0189, 0.0101, 0.0076, 0.0058, 0.0058, 0.0045, 0.0032,\n",
      "         0.0027, 0.0027, 0.0024]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = np.expand_dims(ids_x.astype(int), axis=0)\n",
    "    x = torch.tensor(x).to(device=device)\n",
    "\n",
    "    scores = model(x.long())\n",
    "    _, predictions = scores.max(1)\n",
    "    class_prob = torch.softmax(scores, dim=1)\n",
    "    # get most probable class and its probability:\n",
    "    class_prob, topclass = torch.topk(class_prob, 12, dim=1)\n",
    "    print(topclass)\n",
    "    print(class_prob)\n",
    "    \n",
    "    ys = np.array(topclass.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁almost', '▁on', '▁', '▁of', '▁and', '▁the', '▁come', '▁They', '▁know', '▁I', '▁as', '▁so']\n"
     ]
    }
   ],
   "source": [
    "ys = np.array(topclass.squeeze(0)).tolist()\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
